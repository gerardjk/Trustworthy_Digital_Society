{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe471475-bf5f-4b79-9518-23f520652e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Chrome WebDriver...\n",
      "Starting combined scraping of bond spreads and credit ratings...\n",
      "\n",
      "=========================================\n",
      "PART 1: SCRAPING BOND SPREADS DATA\n",
      "=========================================\n",
      "\n",
      "Navigating to https://www.worldgovernmentbonds.com/spread-historical-data/...\n",
      "Waiting for page to fully load...\n",
      "Found 1 tables on the page\n",
      "\n",
      "TABLE STRUCTURE:\n",
      "Row 0 (HEADER): ['', '', '', 'Spread vs']\n",
      "Row 1 (HEADER): ['', 'Country', '10Y Yield▴', 'Ger', 'Usa', 'Chi', 'Aus']\n",
      "Row 2 (DATA): ['', 'Switzerland', '0.305%', '-224.7 bp', '-407.6 bp', '-132.5 bp', '-398.8 bp']\n",
      "Row 3 (DATA): ['', 'Japan', '1.356%', '-119.6 bp', '-302.5 bp', '-27.4 bp', '-293.7 bp']\n",
      "Row 4 (DATA): ['', 'Taiwan', '1.530%', '-102.2 bp', '-285.1 bp', '-10.0 bp', '-276.3 bp']\n",
      "Using indices: Country=1, USA=4\n",
      "Data row 2, Cell count: 7\n",
      "  Country: 'Switzerland', USA value: '-407.6 bp'\n",
      "Data row 3, Cell count: 7\n",
      "  Country: 'Japan', USA value: '-302.5 bp'\n",
      "Data row 4, Cell count: 7\n",
      "  Country: 'Taiwan', USA value: '-285.1 bp'\n",
      "Data row 5, Cell count: 7\n",
      "  Country: 'China', USA value: '-275.1 bp'\n",
      "Data row 6, Cell count: 7\n",
      "  Country: 'Denmark', USA value: '-205.6 bp'\n",
      "\n",
      "Extracted 70 rows with country and USA spread values\n",
      "\n",
      "First 5 extracted rows:\n",
      "1. Country: 'Switzerland', USA value: '-407.6 bp'\n",
      "2. Country: 'Japan', USA value: '-302.5 bp'\n",
      "3. Country: 'Taiwan', USA value: '-285.1 bp'\n",
      "4. Country: 'China', USA value: '-275.1 bp'\n",
      "5. Country: 'Denmark', USA value: '-205.6 bp'\n",
      "\n",
      "Data saved to government_bond_spreads.csv\n",
      "\n",
      "Preview of the bond spreads data (first 5 rows):\n",
      "       Country  Spread\n",
      "0  Switzerland  -407.6\n",
      "1        Japan  -302.5\n",
      "2       Taiwan  -285.1\n",
      "3        China  -275.1\n",
      "4      Denmark  -205.6\n",
      "\n",
      "=========================================\n",
      "PART 2: SCRAPING CREDIT RATINGS DATA\n",
      "=========================================\n",
      "\n",
      "Navigating to https://www.worldgovernmentbonds.com/world-credit-ratings/...\n",
      "Waiting for page to fully load...\n",
      "Waiting for tables to load...\n",
      "Found 1 tables on the page\n",
      "Found 75 rows in the target table\n",
      "Headers: ['', 'Country▴', 'S&P', \"Moody's\", 'Fitch', 'DBRS']\n",
      "Found S&P column: S&P at index 2\n",
      "Found Moody's column: Moody's at index 3\n",
      "Found Fitch column: Fitch at index 4\n",
      "Found DBRS column: DBRS at index 5 - will be removed\n",
      "Found upgrade indicator for cell: Caa3 [upgrade]\n",
      "Found downgrade indicator for cell: AA+ [downgrade]\n",
      "Found downgrade indicator for cell: B+ [downgrade]\n",
      "Found downgrade indicator for cell: B+ [downgrade]\n",
      "Found downgrade indicator for cell: B2 [downgrade]\n",
      "Found downgrade indicator for cell: AA [downgrade]\n",
      "Found downgrade indicator for cell: Aa3 [downgrade]\n",
      "Found downgrade indicator for cell: AA- [downgrade]\n",
      "Found downgrade indicator for cell: BBB+ [downgrade]\n",
      "Found downgrade indicator for cell: A3 [downgrade]\n",
      "Found upgrade indicator for cell: Ba1 [upgrade]\n",
      "Found upgrade indicator for cell: BBB [upgrade]\n",
      "Found upgrade indicator for cell: BBB [upgrade]\n",
      "Found downgrade indicator for cell: A1 [downgrade]\n",
      "Found downgrade indicator for cell: BB+ [downgrade]\n",
      "Found downgrade indicator for cell: Baa2 [downgrade]\n",
      "Found downgrade indicator for cell: BB+ [downgrade]\n",
      "Found upgrade indicator for cell: A- [upgrade]\n",
      "Found upgrade indicator for cell: Caa1 [upgrade]\n",
      "Found downgrade indicator for cell: AA+ [downgrade]\n",
      "Found downgrade indicator for cell: AA- [downgrade]\n",
      "Found downgrade indicator for cell: AA- [downgrade]\n",
      "Found downgrade indicator for cell: Aa3 [downgrade]\n",
      "Found downgrade indicator for cell: BBB- [downgrade]\n",
      "Found downgrade indicator for cell: Baa2 [downgrade]\n",
      "Found upgrade indicator for cell: BBB- [upgrade]\n",
      "Found upgrade indicator for cell: AA [upgrade]\n",
      "Found upgrade indicator for cell: Aa3 [upgrade]\n",
      "Found downgrade indicator for cell: A [downgrade]\n",
      "Found downgrade indicator for cell: Baa1 [downgrade]\n",
      "Found downgrade indicator for cell: A [downgrade]\n",
      "Found upgrade indicator for cell: BBB [upgrade]\n",
      "Found upgrade indicator for cell: Caa1 [upgrade]\n",
      "Found downgrade indicator for cell: Baa3 [downgrade]\n",
      "Found downgrade indicator for cell: Baa2 [downgrade]\n",
      "Found upgrade indicator for cell: BB+ [upgrade]\n",
      "Found upgrade indicator for cell: B1 [upgrade]\n",
      "Found downgrade indicator for cell: BB [downgrade]\n",
      "Found upgrade indicator for cell: Caa1 [upgrade]\n",
      "Found upgrade indicator for cell: Caa2 [upgrade]\n",
      "Found upgrade indicator for cell: BBB+ [upgrade]\n",
      "Found upgrade indicator for cell: A [upgrade]\n",
      "Found upgrade indicator for cell: A- [upgrade]\n",
      "Found downgrade indicator for cell: BBB- [downgrade]\n",
      "Found downgrade indicator for cell: Baa3 [downgrade]\n",
      "Found downgrade indicator for cell: BBB- [downgrade]\n",
      "Found upgrade indicator for cell: Ba2 [upgrade]\n",
      "Found upgrade indicator for cell: BB+ [upgrade]\n",
      "Found downgrade indicator for cell: A+ [downgrade]\n",
      "Found upgrade indicator for cell: AA- [upgrade]\n",
      "Found upgrade indicator for cell: A3 [upgrade]\n",
      "Found upgrade indicator for cell: A [upgrade]\n",
      "Found upgrade indicator for cell: BB- [upgrade]\n",
      "Found upgrade indicator for cell: Baa1 [upgrade]\n",
      "Found upgrade indicator for cell: A- [upgrade]\n",
      "Found downgrade indicator for cell: Baa1 [downgrade]\n",
      "Found upgrade indicator for cell: B1 [upgrade]\n",
      "Found upgrade indicator for cell: B+ [upgrade]\n",
      "Found downgrade indicator for cell: Aaa [downgrade]\n",
      "Found upgrade indicator for cell: Caa2 [upgrade]\n",
      "Mapped 'S&P' to 'S&P_Numeric' using sp_ratings\n",
      "Mapped 'Moody's' to 'Moody's_Numeric' using moodys_ratings\n",
      "Mapped 'Fitch' to 'Fitch_Numeric' using fitch_ratings\n",
      "\n",
      "Converting ratings for column: S&P\n",
      "Sample values from original column:\n",
      "  1. 'CCC'\n",
      "  2. 'AAA'\n",
      "  3. 'AA+'\n",
      "  4. 'B+ [downgrade]'\n",
      "  5. 'B+'\n",
      "  6. 'AA [downgrade]'\n",
      "  7. 'BBB+ [downgrade]'\n",
      "  8. 'BB'\n",
      "  9. 'BBB [upgrade]'\n",
      "  10. 'AAA'\n",
      "Converting rating: 'CCC'\n",
      "  Base rating: 'CCC'\n",
      "  Base numeric value: 5\n",
      "  Final value with modifier: 5\n",
      "Converting rating: 'AAA'\n",
      "  Base rating: 'AAA'\n",
      "  Base numeric value: 22\n",
      "  Final value with modifier: 22\n",
      "Converting rating: 'AA+'\n",
      "  Base rating: 'AA+'\n",
      "  Base numeric value: 21\n",
      "  Final value with modifier: 21\n",
      "Converting rating: 'B+ [downgrade]'\n",
      "  Found downgrade indicator, subtracting -1/3\n",
      "  Base rating: 'B+'\n",
      "  Base numeric value: 9\n",
      "  Final value with modifier: 8.666666666666666\n",
      "Converting rating: 'B+'\n",
      "  Base rating: 'B+'\n",
      "  Base numeric value: 9\n",
      "  Final value with modifier: 9\n",
      "Converting rating: 'AA [downgrade]'\n",
      "  Found downgrade indicator, subtracting -1/3\n",
      "  Base rating: 'AA'\n",
      "  Base numeric value: 20\n",
      "  Final value with modifier: 19.666666666666668\n",
      "Converting rating: 'BBB+ [downgrade]'\n",
      "  Found downgrade indicator, subtracting -1/3\n",
      "  Base rating: 'BBB+'\n",
      "  Base numeric value: 15\n",
      "  Final value with modifier: 14.666666666666666\n",
      "Converting rating: 'BB'\n",
      "  Base rating: 'BB'\n",
      "  Base numeric value: 11\n",
      "  Final value with modifier: 11\n",
      "Converting rating: 'BBB [upgrade]'\n",
      "  Found upgrade indicator, adding +1/3\n",
      "  Base rating: 'BBB'\n",
      "  Base numeric value: 14\n",
      "  Final value with modifier: 14.333333333333334\n",
      "Converting rating: 'AAA'\n",
      "  Base rating: 'AAA'\n",
      "  Base numeric value: 22\n",
      "  Final value with modifier: 22\n",
      "Converting rating: 'A'\n",
      "  Base rating: 'A'\n",
      "  Base numeric value: 17\n",
      "  Final value with modifier: 17\n",
      "Converting rating: 'A+'\n",
      "  Base rating: 'A+'\n",
      "  Base numeric value: 18\n",
      "  Final value with modifier: 18\n",
      "Converting rating: 'BB+ [downgrade]'\n",
      "  Found downgrade indicator, subtracting -1/3\n",
      "  Base rating: 'BB+'\n",
      "  Base numeric value: 12\n",
      "  Final value with modifier: 11.666666666666666\n",
      "Converting rating: 'A- [upgrade]'\n",
      "  Found upgrade indicator, adding +1/3\n",
      "  Base rating: 'A-'\n",
      "  Base numeric value: 16\n",
      "  Final value with modifier: 16.333333333333332\n",
      "Converting rating: 'A-'\n",
      "  Base rating: 'A-'\n",
      "  Base numeric value: 16\n",
      "  Final value with modifier: 16\n",
      "Converting rating: 'AA-'\n",
      "  Base rating: 'AA-'\n",
      "  Base numeric value: 19\n",
      "  Final value with modifier: 19\n",
      "Converting rating: 'AAA'\n",
      "  Base rating: 'AAA'\n",
      "  Base numeric value: 22\n",
      "  Final value with modifier: 22\n",
      "Converting rating: 'B-'\n",
      "  Base rating: 'B-'\n",
      "  Base numeric value: 7\n",
      "  Final value with modifier: 7\n",
      "Converting rating: 'AA+'\n",
      "  Base rating: 'AA+'\n",
      "  Base numeric value: 21\n",
      "  Final value with modifier: 21\n",
      "Converting rating: 'AA- [downgrade]'\n",
      "  Found downgrade indicator, subtracting -1/3\n",
      "  Base rating: 'AA-'\n",
      "  Base numeric value: 19\n",
      "  Final value with modifier: 18.666666666666668\n",
      "Preview of converted values in S&P_Numeric:\n",
      "  1. 'CCC' → 5.0\n",
      "  2. 'AAA' → 22.0\n",
      "  3. 'AA+' → 21.0\n",
      "  4. 'B+ [downgrade]' → 8.666666666666666\n",
      "  5. 'B+' → 9.0\n",
      "  6. 'AA [downgrade]' → 19.666666666666668\n",
      "  7. 'BBB+ [downgrade]' → 14.666666666666666\n",
      "  8. 'BB' → 11.0\n",
      "  9. 'BBB [upgrade]' → 14.333333333333334\n",
      "  10. 'AAA' → 22.0\n",
      "\n",
      "Converting ratings for column: Moody's\n",
      "Sample values from original column:\n",
      "  1. 'Caa3 [upgrade]'\n",
      "  2. 'Aaa'\n",
      "  3. 'Aa1'\n",
      "  4. 'B2'\n",
      "  5. 'B2 [downgrade]'\n",
      "  6. 'Aa3 [downgrade]'\n",
      "  7. 'A3 [downgrade]'\n",
      "  8. 'Ba1 [upgrade]'\n",
      "  9. 'Baa1'\n",
      "  10. 'Aaa'\n",
      "Preview of converted values in Moody's_Numeric:\n",
      "  1. 'Caa3 [upgrade]' → 4.333333333333333\n",
      "  2. 'Aaa' → 22.0\n",
      "  3. 'Aa1' → 21.0\n",
      "  4. 'B2' → 8.0\n",
      "  5. 'B2 [downgrade]' → 7.666666666666667\n",
      "  6. 'Aa3 [downgrade]' → 18.666666666666668\n",
      "  7. 'A3 [downgrade]' → 15.666666666666666\n",
      "  8. 'Ba1 [upgrade]' → 12.333333333333334\n",
      "  9. 'Baa1' → 15.0\n",
      "  10. 'Aaa' → 22.0\n",
      "\n",
      "Converting ratings for column: Fitch\n",
      "Sample values from original column:\n",
      "  1. 'CCC'\n",
      "  2. 'AAA'\n",
      "  3. 'AA+ [downgrade]'\n",
      "  4. 'B+ [downgrade]'\n",
      "  5. 'B+'\n",
      "  6. 'AA- [downgrade]'\n",
      "  7. '-'\n",
      "  8. 'BB'\n",
      "  9. 'BBB [upgrade]'\n",
      "  10. 'AA+'\n",
      "Preview of converted values in Fitch_Numeric:\n",
      "  1. 'CCC' → 5.0\n",
      "  2. 'AAA' → 22.0\n",
      "  3. 'AA+ [downgrade]' → 20.666666666666668\n",
      "  4. 'B+ [downgrade]' → 8.666666666666666\n",
      "  5. 'B+' → 9.0\n",
      "  6. 'AA- [downgrade]' → 18.666666666666668\n",
      "  7. '-' → nan\n",
      "  8. 'BB' → 11.0\n",
      "  9. 'BBB [upgrade]' → 14.333333333333334\n",
      "  10. 'AA+' → 21.0\n",
      "Saving credit ratings data to CSV...\n",
      "Data saved to world_credit_ratings_with_numeric.csv\n",
      "\n",
      "Indicator Statistics:\n",
      "Ratings with [upgrade] indicator: 29\n",
      "Ratings with [downgrade] indicator: 31\n",
      "Ratings without indicators: 162\n",
      "\n",
      "Preview of the credit ratings data (showing first few countries with ratings):\n",
      "                S&P  S&P_Numeric         Moody's  Moody's_Numeric            Fitch  Fitch_Numeric\n",
      "0               CCC     5.000000  Caa3 [upgrade]         4.333333              CCC       5.000000\n",
      "1               AAA    22.000000             Aaa        22.000000              AAA      22.000000\n",
      "2               AA+    21.000000             Aa1        21.000000  AA+ [downgrade]      20.666667\n",
      "3    B+ [downgrade]     8.666667              B2         8.000000   B+ [downgrade]       8.666667\n",
      "4                B+     9.000000  B2 [downgrade]         7.666667               B+       9.000000\n",
      "\n",
      "=========================================\n",
      "SCRAPING SUMMARY\n",
      "=========================================\n",
      "✅ Bond spreads data successfully scraped and saved to 'government_bond_spreads.csv'\n",
      "✅ Credit ratings data successfully scraped and saved to 'world_credit_ratings_with_numeric.csv'\n",
      "\n",
      "Both datasets were successfully scraped! 🎉\n",
      "\n",
      "WebDriver closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize the WebDriver\n",
    "print(\"Initializing Chrome WebDriver...\")\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Rating conversion dictionaries for each agency\n",
    "# Higher number = better credit rating\n",
    "\n",
    "# S&P ratings conversion (AAA = 22, D = 1)\n",
    "sp_ratings = {\n",
    "    'AAA': 22, 'AA+': 21, 'AA': 20, 'AA-': 19,\n",
    "    'A+': 18, 'A': 17, 'A-': 16,\n",
    "    'BBB+': 15, 'BBB': 14, 'BBB-': 13,\n",
    "    'BB+': 12, 'BB': 11, 'BB-': 10,\n",
    "    'B+': 9, 'B': 8, 'B-': 7,\n",
    "    'CCC+': 6, 'CCC': 5, 'CCC-': 4,\n",
    "    'CC': 3, 'C': 2, 'D': 1,\n",
    "    # Note: SD and RD are converted to 'D' in extract_base_rating()\n",
    "}\n",
    "\n",
    "# Moody's ratings conversion (Aaa = 22, C = 1)\n",
    "moodys_ratings = {\n",
    "    'Aaa': 22, 'Aa1': 21, 'Aa2': 20, 'Aa3': 19,\n",
    "    'A1': 18, 'A2': 17, 'A3': 16,\n",
    "    'Baa1': 15, 'Baa2': 14, 'Baa3': 13,\n",
    "    'Ba1': 12, 'Ba2': 11, 'Ba3': 10,\n",
    "    'B1': 9, 'B2': 8, 'B3': 7,\n",
    "    'Caa1': 6, 'Caa2': 5, 'Caa3': 4,\n",
    "    'Ca': 3, 'C': 1\n",
    "}\n",
    "\n",
    "# Fitch ratings conversion (AAA = 22, D = 1)\n",
    "fitch_ratings = {\n",
    "    'AAA': 22, 'AA+': 21, 'AA': 20, 'AA-': 19,\n",
    "    'A+': 18, 'A': 17, 'A-': 16,\n",
    "    'BBB+': 15, 'BBB': 14, 'BBB-': 13,\n",
    "    'BB+': 12, 'BB': 11, 'BB-': 10,\n",
    "    'B+': 9, 'B': 8, 'B-': 7,\n",
    "    'CCC+': 6, 'CCC': 5, 'CCC-': 4,\n",
    "    'CC': 3, 'C': 2, 'D': 1\n",
    "    # Note: RD is converted to 'D' in extract_base_rating()\n",
    "}\n",
    "\n",
    "# Counter for debug logging\n",
    "debug_count = 0\n",
    "\n",
    "# Helper function to extract base rating (without outlook or watch indicators)\n",
    "def extract_base_rating(rating_text):\n",
    "    # Strip upgrade/downgrade indicators (but don't remove them completely from the original data)\n",
    "    clean_rating = rating_text.replace('[upgrade]', '').replace('[downgrade]', '').strip()\n",
    "    \n",
    "    # Handle special cases\n",
    "    if clean_rating in ['N/A', '-', '', 'NR']:\n",
    "        return 'N/A'\n",
    "    if clean_rating in ['SD', 'RD']:\n",
    "        return 'D'  # Treat Selective Default and Restricted Default as Default\n",
    "    \n",
    "    # Extract the rating code using regex\n",
    "    # This will extract the letter-based rating without outlook indicators\n",
    "    match = re.search(r'([A-Za-z]{1,3}[\\+\\-]?[123]?)', clean_rating)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return clean_rating\n",
    "\n",
    "# Convert rating to numeric value\n",
    "def convert_rating_to_numeric(rating_text, rating_dict):\n",
    "    global debug_count\n",
    "    \n",
    "    if not rating_text:\n",
    "        return None\n",
    "    \n",
    "    # Debug print only for first few conversions\n",
    "    debug = debug_count < 20\n",
    "    \n",
    "    if debug:\n",
    "        # Debug: Print the exact rating text received\n",
    "        print(f\"Converting rating: '{rating_text}'\")\n",
    "    \n",
    "    # Check for upgrade/downgrade indicators - ensure it's a string first\n",
    "    upgrade_modifier = 0\n",
    "    if isinstance(rating_text, str):\n",
    "        if '[upgrade]' in rating_text:\n",
    "            upgrade_modifier = 1/3  # Add 1/3 point for upgrade\n",
    "            if debug:\n",
    "                print(f\"  Found upgrade indicator, adding +1/3\")\n",
    "        elif '[downgrade]' in rating_text:\n",
    "            upgrade_modifier = -1/3  # Subtract 1/3 point for downgrade\n",
    "            if debug:\n",
    "                print(f\"  Found downgrade indicator, subtracting -1/3\")\n",
    "        \n",
    "    # Get base rating without indicators\n",
    "    base_rating = extract_base_rating(rating_text)\n",
    "    if debug:\n",
    "        print(f\"  Base rating: '{base_rating}'\")\n",
    "    \n",
    "    # Handle N/A and similar cases\n",
    "    if base_rating == 'N/A':\n",
    "        if debug:\n",
    "            print(f\"  Rating is N/A, returning None\")\n",
    "        return None\n",
    "        \n",
    "    # Get the base numeric value\n",
    "    base_numeric = rating_dict.get(base_rating, None)\n",
    "    if debug:\n",
    "        print(f\"  Base numeric value: {base_numeric}\")\n",
    "    \n",
    "    # Return None if rating not found\n",
    "    if base_numeric is None:\n",
    "        if debug:\n",
    "            print(f\"  Rating not found in dictionary, returning None\")\n",
    "        return None\n",
    "        \n",
    "    # Apply the upgrade/downgrade modifier\n",
    "    final_value = base_numeric + upgrade_modifier\n",
    "    if debug:\n",
    "        print(f\"  Final value with modifier: {final_value}\")\n",
    "    \n",
    "    # Increment debug counter\n",
    "    debug_count += 1\n",
    "        \n",
    "    return final_value\n",
    "\n",
    "# First script function: Scrape bond spreads - CORRECTED VERSION\n",
    "# First script function: Scrape bond spreads - HARDCODED VERSION\n",
    "# First script function: Scrape bond spreads - FIXED INDICES\n",
    "def scrape_bond_spreads():\n",
    "    print(\"\\n=========================================\")\n",
    "    print(\"PART 1: SCRAPING BOND SPREADS DATA\")\n",
    "    print(\"=========================================\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the website\n",
    "        url = \"https://www.worldgovernmentbonds.com/spread-historical-data/\"\n",
    "        print(f\"Navigating to {url}...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Add a longer wait to ensure all elements load\n",
    "        print(\"Waiting for page to fully load...\")\n",
    "        time.sleep(5)  # Wait 5 seconds for any dynamic content\n",
    "        \n",
    "        # Find all tables directly\n",
    "        tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "        print(f\"Found {len(tables)} tables on the page\")\n",
    "        \n",
    "        if not tables:\n",
    "            print(\"No tables found, cannot proceed\")\n",
    "            return False\n",
    "            \n",
    "        # Get the largest table\n",
    "        target_table = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, \"tr\")))\n",
    "        all_rows = target_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        \n",
    "        # Print the first few rows to confirm structure\n",
    "        print(\"\\nTABLE STRUCTURE:\")\n",
    "        for i, row in enumerate(all_rows[:5]):\n",
    "            headers = row.find_elements(By.TAG_NAME, \"th\")\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            if headers:\n",
    "                header_texts = [h.text.strip() for h in headers]\n",
    "                print(f\"Row {i} (HEADER): {header_texts}\")\n",
    "            \n",
    "            if cells:\n",
    "                cell_texts = [c.text.strip() for c in cells]\n",
    "                print(f\"Row {i} (DATA): {cell_texts}\")\n",
    "        \n",
    "        # CORRECT INDICES based on debug output\n",
    "        country_column_index = 1  # \"Country\" is at index 1\n",
    "        usa_column_index = 4      # \"Usa\" is at index 4\n",
    "        \n",
    "        print(f\"Using indices: Country={country_column_index}, USA={usa_column_index}\")\n",
    "        \n",
    "        # Start from row 2 (index 2) to skip headers\n",
    "        data_rows = []\n",
    "        data_start_row = 2\n",
    "        \n",
    "        for i, row in enumerate(all_rows[data_start_row:]):\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            # Debug first few rows\n",
    "            if i < 5:\n",
    "                print(f\"Data row {i+data_start_row}, Cell count: {len(cells)}\")\n",
    "                if len(cells) > max(country_column_index, usa_column_index):\n",
    "                    country = cells[country_column_index].text.strip()\n",
    "                    usa_value = cells[usa_column_index].text.strip()\n",
    "                    print(f\"  Country: '{country}', USA value: '{usa_value}'\")\n",
    "            \n",
    "            # Skip rows with insufficient cells\n",
    "            if len(cells) <= max(country_column_index, usa_column_index):\n",
    "                continue\n",
    "                \n",
    "            country = cells[country_column_index].text.strip()\n",
    "            usa_value = cells[usa_column_index].text.strip()\n",
    "            \n",
    "            # Only add rows with both country and USA value\n",
    "            if country and usa_value:\n",
    "                data_rows.append([country, usa_value])\n",
    "        \n",
    "        print(f\"\\nExtracted {len(data_rows)} rows with country and USA spread values\")\n",
    "        \n",
    "        # Print the first few rows to confirm\n",
    "        print(\"\\nFirst 5 extracted rows:\")\n",
    "        for i, row in enumerate(data_rows[:5]):\n",
    "            print(f\"{i+1}. Country: '{row[0]}', USA value: '{row[1]}'\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        if data_rows:\n",
    "            df = pd.DataFrame(data_rows, columns=[\"Country\", \"Spread\"])\n",
    "            \n",
    "            # Remove any bp or % symbols and convert to numeric\n",
    "            df[\"Spread\"] = df[\"Spread\"].str.replace(',', '').str.replace('%', '').str.replace('bp', '').str.strip()\n",
    "            df[\"Spread\"] = pd.to_numeric(df[\"Spread\"], errors='coerce')\n",
    "            \n",
    "            # Remove rows with empty country or NaN spread\n",
    "            df = df[df['Country'].str.strip() != '']\n",
    "            df = df.dropna(subset=['Spread'])\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_file = \"government_bond_spreads.csv\"\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"\\nData saved to {output_file}\")\n",
    "            \n",
    "            # Print preview\n",
    "            print(\"\\nPreview of the bond spreads data (first 5 rows):\")\n",
    "            print(df.head().to_string())\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            print(\"No data rows extracted\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during bond spreads scraping: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Second script function: Scrape credit ratings\n",
    "def scrape_credit_ratings():\n",
    "    print(\"\\n=========================================\")\n",
    "    print(\"PART 2: SCRAPING CREDIT RATINGS DATA\")\n",
    "    print(\"=========================================\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the website\n",
    "        url = \"https://www.worldgovernmentbonds.com/world-credit-ratings/\"\n",
    "        print(f\"Navigating to {url}...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Add a longer wait to ensure all elements load\n",
    "        print(\"Waiting for page to fully load...\")\n",
    "        time.sleep(5)  # Wait 5 seconds for any dynamic content\n",
    "        \n",
    "        # Wait for tables to load\n",
    "        print(\"Waiting for tables to load...\")\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "        )\n",
    "        \n",
    "        # Find all tables\n",
    "        tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "        print(f\"Found {len(tables)} tables on the page\")\n",
    "        \n",
    "        # Use the largest table\n",
    "        if tables:\n",
    "            target_table = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, \"tr\")))\n",
    "            \n",
    "            # Extract table structure\n",
    "            rows = target_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            print(f\"Found {len(rows)} rows in the target table\")\n",
    "            \n",
    "            # Extract headers\n",
    "            header_row = rows[0]\n",
    "            headers = [header.text.strip() for header in header_row.find_elements(By.TAG_NAME, \"th\")]\n",
    "            print(f\"Headers: {headers}\")\n",
    "            \n",
    "            # Find the indexes of the S&P, Moody's, and Fitch columns\n",
    "            rating_column_indices = {}\n",
    "            dbrs_index = None\n",
    "            \n",
    "            for i, header in enumerate(headers):\n",
    "                header_lower = header.lower()\n",
    "                if \"s&p\" in header_lower:\n",
    "                    rating_column_indices[\"S&P\"] = i\n",
    "                    print(f\"Found S&P column: {header} at index {i}\")\n",
    "                elif \"moody\" in header_lower:\n",
    "                    rating_column_indices[\"Moody's\"] = i\n",
    "                    print(f\"Found Moody's column: {header} at index {i}\")\n",
    "                elif \"fitch\" in header_lower:\n",
    "                    rating_column_indices[\"Fitch\"] = i\n",
    "                    print(f\"Found Fitch column: {header} at index {i}\")\n",
    "                elif \"dbrs\" in header_lower:\n",
    "                    dbrs_index = i\n",
    "                    print(f\"Found DBRS column: {header} at index {i} - will be removed\")\n",
    "            \n",
    "            # Create specific selectors for red and teal indicators\n",
    "            red_selector = \"i.w3-text-red.fa.fa-circle.w3-tiny\"\n",
    "            teal_selector = \"i.w3-text-teal.fa.fa-circle.w3-tiny\"\n",
    "            \n",
    "            # More general fallback selectors\n",
    "            red_fallback_selector = \"i[class*='w3-text-red'][class*='fa-circle']\"\n",
    "            teal_fallback_selector = \"i[class*='w3-text-teal'][class*='fa-circle']\"\n",
    "            \n",
    "            # Extract data rows with indicators\n",
    "            data_rows = []\n",
    "            for row in rows[1:]:  # Skip header row\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if cells and len(cells) > 0:\n",
    "                    row_data = []\n",
    "                    \n",
    "                    for i, cell in enumerate(cells):\n",
    "                        # Skip the DBRS column\n",
    "                        if i == dbrs_index:\n",
    "                            continue\n",
    "                            \n",
    "                        # Only process cells that exist in the row\n",
    "                        if i < len(cells):\n",
    "                            cell_text = cell.text.strip()\n",
    "                            \n",
    "                            # If this is a rating column, check for indicators\n",
    "                            if i in rating_column_indices.values():\n",
    "                                # Look for red indicator\n",
    "                                red_icons = cell.find_elements(By.CSS_SELECTOR, red_selector)\n",
    "                                if not red_icons:  # Try fallback if exact match fails\n",
    "                                    red_icons = cell.find_elements(By.CSS_SELECTOR, red_fallback_selector)\n",
    "                                \n",
    "                                # Look for teal indicator\n",
    "                                teal_icons = cell.find_elements(By.CSS_SELECTOR, teal_selector)\n",
    "                                if not teal_icons:  # Try fallback if exact match fails\n",
    "                                    teal_icons = cell.find_elements(By.CSS_SELECTOR, teal_fallback_selector)\n",
    "                                \n",
    "                                # Add indicator to cell text\n",
    "                                if red_icons:\n",
    "                                    cell_text = f\"{cell_text} [downgrade]\"\n",
    "                                    print(f\"Found downgrade indicator for cell: {cell_text}\")\n",
    "                                elif teal_icons:\n",
    "                                    cell_text = f\"{cell_text} [upgrade]\"\n",
    "                                    print(f\"Found upgrade indicator for cell: {cell_text}\")\n",
    "                            \n",
    "                            row_data.append(cell_text)\n",
    "                    \n",
    "                    # Only add rows with data\n",
    "                    if row_data:\n",
    "                        data_rows.append(row_data)\n",
    "            \n",
    "            # Create new headers without DBRS\n",
    "            new_headers = []\n",
    "            for i, header in enumerate(headers):\n",
    "                if i != dbrs_index:\n",
    "                    new_headers.append(header)\n",
    "            \n",
    "            # Create DataFrame\n",
    "            if new_headers and data_rows:\n",
    "                # Make sure the dimensions match\n",
    "                if len(new_headers) != len(data_rows[0]):\n",
    "                    print(f\"Warning: Headers count ({len(new_headers)}) doesn't match column count in first row ({len(data_rows[0])})\")\n",
    "                    \n",
    "                    if len(new_headers) > len(data_rows[0]):\n",
    "                        # Truncate headers to match data\n",
    "                        new_headers = new_headers[:len(data_rows[0])]\n",
    "                    else:\n",
    "                        # Add generic column names if needed\n",
    "                        while len(new_headers) < len(data_rows[0]):\n",
    "                            new_headers.append(f\"Column_{len(new_headers)+1}\")\n",
    "                \n",
    "                # Create DataFrame with headers and data\n",
    "                df = pd.DataFrame(data_rows, columns=new_headers)\n",
    "                \n",
    "                # Add numeric conversion columns for each rating agency\n",
    "                \n",
    "                # Map the original column names to their rating dictionaries\n",
    "                rating_mapping = {}\n",
    "                \n",
    "                # Find exact column names\n",
    "                for agency, abbr in [(\"s&p\", \"S&P\"), (\"moody\", \"Moody's\"), (\"fitch\", \"Fitch\")]:\n",
    "                    found = False\n",
    "                    for header in new_headers:\n",
    "                        if agency in header.lower():\n",
    "                            # Fix variable name for Moody's ratings\n",
    "                            if agency == \"moody\":\n",
    "                                rating_dict_name = \"moodys_ratings\"\n",
    "                            else:\n",
    "                                rating_dict_name = f\"{agency.replace('&', '')}_ratings\"\n",
    "                            \n",
    "                            rating_mapping[header] = (f\"{abbr}_Numeric\", globals()[rating_dict_name])\n",
    "                            print(f\"Mapped '{header}' to '{abbr}_Numeric' using {rating_dict_name}\")\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        print(f\"Warning: Could not find column for {abbr}\")\n",
    "                \n",
    "                # Add numeric conversion columns\n",
    "                for col_name, (numeric_col_name, rating_dict) in rating_mapping.items():\n",
    "                    print(f\"\\nConverting ratings for column: {col_name}\")\n",
    "                    # Print a few sample values from the original column\n",
    "                    print(\"Sample values from original column:\")\n",
    "                    for i, val in enumerate(df[col_name].head(10)):\n",
    "                        print(f\"  {i+1}. '{val}'\")\n",
    "                    \n",
    "                    # Convert to numeric\n",
    "                    df[numeric_col_name] = df[col_name].apply(\n",
    "                        lambda x: convert_rating_to_numeric(x, rating_dict)\n",
    "                    )\n",
    "                    \n",
    "                    # Print result preview\n",
    "                    print(f\"Preview of converted values in {numeric_col_name}:\")\n",
    "                    for i, (orig, num) in enumerate(zip(df[col_name].head(10), df[numeric_col_name].head(10))):\n",
    "                        print(f\"  {i+1}. '{orig}' → {num}\")\n",
    "                \n",
    "                # Add average rating column (ignoring None values)\n",
    "                df['Average_Rating'] = df[['S&P_Numeric', 'Moody\\'s_Numeric', 'Fitch_Numeric']].mean(axis=1, skipna=True).round(2)\n",
    "                \n",
    "                # Add count of available ratings column\n",
    "                df['Ratings_Count'] = df[['S&P_Numeric', 'Moody\\'s_Numeric', 'Fitch_Numeric']].count(axis=1)\n",
    "                \n",
    "                print(\"Saving credit ratings data to CSV...\")\n",
    "                output_file = \"world_credit_ratings_with_numeric.csv\"\n",
    "                df.to_csv(output_file, index=False)\n",
    "                print(f\"Data saved to {output_file}\")\n",
    "                \n",
    "                # Display count of upgrade/downgrade indicators\n",
    "                indicator_stats = {\n",
    "                    'upgrade': 0,\n",
    "                    'downgrade': 0,\n",
    "                    'no_indicator': 0\n",
    "                }\n",
    "                \n",
    "                # Check all rating columns for indicator counts\n",
    "                for header in new_headers:\n",
    "                    if any(agency in header.lower() for agency in ['s&p', 'moody', 'fitch']):\n",
    "                        for val in df[header]:\n",
    "                            if isinstance(val, str):\n",
    "                                if '[upgrade]' in val:\n",
    "                                    indicator_stats['upgrade'] += 1\n",
    "                                elif '[downgrade]' in val:\n",
    "                                    indicator_stats['downgrade'] += 1\n",
    "                                else:\n",
    "                                    indicator_stats['no_indicator'] += 1\n",
    "                \n",
    "                print(\"\\nIndicator Statistics:\")\n",
    "                print(f\"Ratings with [upgrade] indicator: {indicator_stats['upgrade']}\")\n",
    "                print(f\"Ratings with [downgrade] indicator: {indicator_stats['downgrade']}\")\n",
    "                print(f\"Ratings without indicators: {indicator_stats['no_indicator']}\")\n",
    "                \n",
    "                # Print preview showing both original and numeric columns\n",
    "                print(\"\\nPreview of the credit ratings data (showing first few countries with ratings):\")\n",
    "                \n",
    "                try:\n",
    "                    # Create a preview with any available columns\n",
    "                    available_columns = df.columns.tolist()\n",
    "                    \n",
    "                    # Try to find a good first column that might contain country names\n",
    "                    first_column = available_columns[0]  # Default to first column\n",
    "                    for col in available_columns:\n",
    "                        if col.lower() == 'country':\n",
    "                            first_column = col\n",
    "                            print(f\"Using column '{col}' as country column\")\n",
    "                            break\n",
    "                    \n",
    "                    # Try to find agency columns\n",
    "                    preview_columns = [first_column]\n",
    "                    for agency in ['S&P', 'Moody\\'s', 'Fitch']:\n",
    "                        # Find original rating column\n",
    "                        agency_cols = [col for col in available_columns if agency.lower() in col.lower() and 'numeric' not in col.lower()]\n",
    "                        # Find numeric rating column\n",
    "                        numeric_cols = [col for col in available_columns if f\"{agency}_Numeric\".lower() in col.lower()]\n",
    "                        \n",
    "                        if agency_cols:\n",
    "                            preview_columns.append(agency_cols[0])\n",
    "                        if numeric_cols:\n",
    "                            preview_columns.append(numeric_cols[0])\n",
    "                    \n",
    "                    # Print preview\n",
    "                    print(df[preview_columns].head(5).to_string())\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Could not display preview due to error: {e}\")\n",
    "                    print(\"Displaying first few rows with all columns instead:\")\n",
    "                    print(df.head(3))\n",
    "                \n",
    "                return True\n",
    "                \n",
    "            else:\n",
    "                print(\"Could not extract proper credit ratings data\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"No tables found on the credit ratings page\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during credit ratings scraping: {e}\")\n",
    "        \n",
    "        # Save the page source in case of error\n",
    "        with open(\"credit_ratings_error_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(driver.page_source)\n",
    "        print(\"Saved page source to 'credit_ratings_error_page.html' for debugging\")\n",
    "        return False\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    print(\"Starting combined scraping of bond spreads and credit ratings...\")\n",
    "    \n",
    "    # First, scrape bond spreads\n",
    "    spreads_successful = scrape_bond_spreads()\n",
    "    \n",
    "    # Then, scrape credit ratings\n",
    "    ratings_successful = scrape_credit_ratings()\n",
    "    \n",
    "    # Summary of what was accomplished\n",
    "    print(\"\\n=========================================\")\n",
    "    print(\"SCRAPING SUMMARY\")\n",
    "    print(\"=========================================\")\n",
    "    \n",
    "    if spreads_successful:\n",
    "        print(\"✅ Bond spreads data successfully scraped and saved to 'government_bond_spreads.csv'\")\n",
    "    else:\n",
    "        print(\"❌ Failed to scrape bond spreads data\")\n",
    "        \n",
    "    if ratings_successful:\n",
    "        print(\"✅ Credit ratings data successfully scraped and saved to 'world_credit_ratings_with_numeric.csv'\")\n",
    "    else:\n",
    "        print(\"❌ Failed to scrape credit ratings data\")\n",
    "    \n",
    "    if spreads_successful and ratings_successful:\n",
    "        print(\"\\nBoth datasets were successfully scraped! 🎉\")\n",
    "    elif spreads_successful or ratings_successful:\n",
    "        print(\"\\nPartial success: only one dataset was scraped successfully.\")\n",
    "    else:\n",
    "        print(\"\\nFailed to scrape both datasets.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred in the main execution: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "    print(\"\\nWebDriver closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c83a254-13c6-4848-a76c-290adea60bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the CSV files...\n",
      "Loaded bond spreads data with 70 rows\n",
      "Bond spreads columns: ['Country', 'Spread']\n",
      "\n",
      "Sample bond spreads data (first 5 rows):\n",
      "       Country  Spread\n",
      "0  Switzerland  -407.6\n",
      "1        Japan  -302.5\n",
      "2       Taiwan  -285.1\n",
      "3        China  -275.1\n",
      "4      Denmark  -205.6\n",
      "\n",
      "Loaded credit ratings data with 74 rows\n",
      "Credit ratings columns: ['Unnamed: 0', 'Country▴', 'S&P', \"Moody's\", 'Fitch', 'S&P_Numeric', \"Moody's_Numeric\", 'Fitch_Numeric', 'Average_Rating', 'Ratings_Count']\n",
      "\n",
      "Sample credit ratings data (first 5 rows):\n",
      "   Unnamed: 0    Country▴             S&P         Moody's            Fitch  S&P_Numeric  Moody's_Numeric  Fitch_Numeric  Average_Rating  Ratings_Count\n",
      "0         NaN   Argentina             CCC  Caa3 [upgrade]              CCC     5.000000         4.333333       5.000000            4.78              3\n",
      "1         NaN   Australia             AAA             Aaa              AAA    22.000000        22.000000      22.000000           22.00              3\n",
      "2         NaN     Austria             AA+             Aa1  AA+ [downgrade]    21.000000        21.000000      20.666667           20.89              3\n",
      "3         NaN     Bahrain  B+ [downgrade]              B2   B+ [downgrade]     8.666667         8.000000       8.666667            8.44              3\n",
      "4         NaN  Bangladesh              B+  B2 [downgrade]               B+     9.000000         7.666667       9.000000            8.56              3\n",
      "\n",
      "Using 'Country▴' as the country column for ratings data.\n",
      "\n",
      "Cleaning country names...\n",
      "\n",
      "Example of country name cleaning in spreads data:\n",
      "\n",
      "Example of country name cleaning in ratings data:\n",
      "\n",
      "Merging datasets on cleaned country names...\n",
      "\n",
      "Successfully merged 70 countries\n",
      "Original spread_df had 70 countries\n",
      "Original ratings_df had 74 countries\n",
      "\n",
      "Countries in spread data but not in ratings data: 0\n",
      "\n",
      "Countries in ratings data but not in spread data: 4\n",
      "Sample unmatched ratings countries (up to 10):\n",
      "  Venezuela\n",
      "  Thailand\n",
      "  Argentina\n",
      "  Latvia\n",
      "\n",
      "Sorted data by Average_Rating (descending)\n",
      "\n",
      "Merged data saved to credit_ratings_and_spreads.csv\n",
      "\n",
      "Preview of the merged data (first 5 rows):\n",
      "        Country  Spread  Unnamed: 0  S&P Moody's Fitch  S&P_Numeric  Moody's_Numeric  Fitch_Numeric  Average_Rating  Ratings_Count\n",
      "0   Switzerland  -407.6         NaN  AAA     Aaa   AAA         22.0             22.0           22.0            22.0              3\n",
      "6     Singapore  -195.9         NaN  AAA     Aaa   AAA         22.0             22.0           22.0            22.0              3\n",
      "31       Norway   -46.8         NaN  AAA     Aaa   AAA         22.0             22.0           22.0            22.0              3\n",
      "9   Netherlands  -158.9         NaN  AAA     Aaa   AAA         22.0             22.0           22.0            22.0              3\n",
      "7       Germany  -182.9         NaN  AAA     Aaa   AAA         22.0             22.0           22.0            22.0              3\n",
      "\n",
      "Final dataset has 70 rows and 11 columns\n",
      "Columns: ['Country', 'Spread', 'Unnamed: 0', 'S&P', \"Moody's\", 'Fitch', 'S&P_Numeric', \"Moody's_Numeric\", 'Fitch_Numeric', 'Average_Rating', 'Ratings_Count']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_country_name(name):\n",
    "    \"\"\"\n",
    "    Clean the country name by removing any asterisks and parentheses,\n",
    "    and stripping whitespace.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "    \n",
    "    # Remove (*) and any other parenthetical expressions\n",
    "    name = re.sub(r'\\s*\\([^)]*\\)\\s*', '', name)\n",
    "    \n",
    "    # Strip any remaining whitespace\n",
    "    return name.strip()\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    print(\"Loading the CSV files...\")\n",
    "    \n",
    "    # Load bond spreads data\n",
    "    spread_df = pd.read_csv(\"government_bond_spreads.csv\")\n",
    "    print(f\"Loaded bond spreads data with {len(spread_df)} rows\")\n",
    "    print(f\"Bond spreads columns: {spread_df.columns.tolist()}\")\n",
    "    print(\"\\nSample bond spreads data (first 5 rows):\")\n",
    "    print(spread_df.head().to_string())\n",
    "    \n",
    "    # Load credit ratings data\n",
    "    ratings_df = pd.read_csv(\"world_credit_ratings_with_numeric.csv\")\n",
    "    print(f\"\\nLoaded credit ratings data with {len(ratings_df)} rows\")\n",
    "    print(f\"Credit ratings columns: {ratings_df.columns.tolist()}\")\n",
    "    print(\"\\nSample credit ratings data (first 5 rows):\")\n",
    "    print(ratings_df.head().to_string())\n",
    "    \n",
    "    # FIX: Correctly identify the country column in the ratings dataframe\n",
    "    # Looking at the sample output, it seems 'Country▴' is the correct column name\n",
    "    country_column = 'Country▴'\n",
    "    print(f\"\\nUsing '{country_column}' as the country column for ratings data.\")\n",
    "    \n",
    "    # Clean country names in both dataframes\n",
    "    print(\"\\nCleaning country names...\")\n",
    "    \n",
    "    # Clean country names in spread data\n",
    "    spread_df['Country_Clean'] = spread_df['Country'].apply(clean_country_name)\n",
    "    print(\"\\nExample of country name cleaning in spreads data:\")\n",
    "    for idx, (orig, cleaned) in enumerate(zip(spread_df['Country'].head(10), spread_df['Country_Clean'].head(10))):\n",
    "        if orig != cleaned:\n",
    "            print(f\"  {orig} -> {cleaned}\")\n",
    "    \n",
    "    # Clean country names in ratings data\n",
    "    ratings_df['Country_Clean'] = ratings_df[country_column].apply(clean_country_name)\n",
    "    print(\"\\nExample of country name cleaning in ratings data:\")\n",
    "    for idx, (orig, cleaned) in enumerate(zip(ratings_df[country_column].head(10), ratings_df['Country_Clean'].head(10))):\n",
    "        if orig != cleaned:\n",
    "            print(f\"  {orig} -> {cleaned}\")\n",
    "    \n",
    "    # Merge datasets on the cleaned country names\n",
    "    print(\"\\nMerging datasets on cleaned country names...\")\n",
    "    merged_df = pd.merge(\n",
    "        spread_df, \n",
    "        ratings_df,\n",
    "        left_on='Country_Clean',\n",
    "        right_on='Country_Clean',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Count the matches\n",
    "    print(f\"\\nSuccessfully merged {len(merged_df)} countries\")\n",
    "    print(f\"Original spread_df had {len(spread_df)} countries\")\n",
    "    print(f\"Original ratings_df had {len(ratings_df)} countries\")\n",
    "    \n",
    "    # Count how many countries didn't match\n",
    "    unmatched_spreads = set(spread_df['Country_Clean']) - set(ratings_df['Country_Clean'])\n",
    "    unmatched_ratings = set(ratings_df['Country_Clean']) - set(spread_df['Country_Clean'])\n",
    "    \n",
    "    print(f\"\\nCountries in spread data but not in ratings data: {len(unmatched_spreads)}\")\n",
    "    if unmatched_spreads:\n",
    "        print(\"Sample unmatched spreads countries (up to 10):\")\n",
    "        for country in list(unmatched_spreads)[:10]:\n",
    "            print(f\"  {country}\")\n",
    "    \n",
    "    print(f\"\\nCountries in ratings data but not in spread data: {len(unmatched_ratings)}\")\n",
    "    if unmatched_ratings:\n",
    "        print(\"Sample unmatched ratings countries (up to 10):\")\n",
    "        for country in list(unmatched_ratings)[:10]:\n",
    "            print(f\"  {country}\")\n",
    "    \n",
    "    # Reorganize columns in the final dataset\n",
    "    # Keep only the original Country column from spread_df and drop the cleaning columns\n",
    "    cols_to_keep = ['Country', 'Spread']  # Start with these columns from spread_df\n",
    "    \n",
    "    # Add all columns from ratings_df except the country column and Country_Clean\n",
    "    for col in ratings_df.columns:\n",
    "        if col != country_column and col != 'Country_Clean':\n",
    "            cols_to_keep.append(col)\n",
    "    \n",
    "    # Make sure all columns in cols_to_keep exist in the merged dataframe\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in merged_df.columns]\n",
    "    \n",
    "    # Reorder columns\n",
    "    merged_df = merged_df[cols_to_keep]\n",
    "    \n",
    "    # Sort by average rating (if available) or alphabetically by country\n",
    "    if 'Average_Rating' in merged_df.columns:\n",
    "        merged_df = merged_df.sort_values(by='Average_Rating', ascending=False)\n",
    "        print(\"\\nSorted data by Average_Rating (descending)\")\n",
    "    else:\n",
    "        merged_df = merged_df.sort_values(by='Country')\n",
    "        print(\"\\nSorted data alphabetically by Country\")\n",
    "    \n",
    "    # Save the merged dataset\n",
    "    output_file = \"credit_ratings_and_spreads.csv\"\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nMerged data saved to {output_file}\")\n",
    "    \n",
    "    # Print a preview of the final merged data\n",
    "    print(\"\\nPreview of the merged data (first 5 rows):\")\n",
    "    print(merged_df.head().to_string())\n",
    "    \n",
    "    # Print column stats of the final merged data\n",
    "    print(f\"\\nFinal dataset has {len(merged_df)} rows and {len(merged_df.columns)} columns\")\n",
    "    print(f\"Columns: {merged_df.columns.tolist()}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure both CSV files are in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()  # Print full traceback for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09e0fd34-ee92-4968-b546-ff9a93101d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/4hl523pd7rs6vzvf8bkrgz580000gn/T/ipykernel_89145/4132776333.py:144: RuntimeWarning: All-NaN axis encountered\n",
      "  y    = np.nanmax([row.get(c) for c in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved → bond_spreads_vs_ratings.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Bond spreads vs. sovereign credit ratings\n",
    "\n",
    "• 12×12-inch figure, double fonts\n",
    "• Investment-grade vs. speculative shading\n",
    "• Vertical x = 0 reference line\n",
    "• Vertical ties between multiple agency ratings per country\n",
    "• PNG flags (any size) or 2-letter ISO fallback\n",
    "• Correlation line with coefficient displayed\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# ---------------------------------------------------------------- paths -------\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:                    # e.g. Jupyter\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "CSV_FILE = BASE_DIR / \"credit_ratings_and_spreads.csv\"\n",
    "ICON_DIR = BASE_DIR / \"flag_icons\"        # us.png, gb.png, au.png, …\n",
    "\n",
    "# ---------------------------------------------------------------- ISO map ----\n",
    "COUNTRY_TO_CODE =  {\n",
    "    \"Switzerland\": \"ch\", \"Singapore\": \"sg\", \"Norway\": \"no\", \"Netherlands\": \"nl\",\n",
    "    \"Germany\": \"de\", \"Australia\": \"au\", \"Sweden\": \"se\", \"Denmark\": \"dk\",\n",
    "    \"Canada\": \"ca\", \"New Zealand\": \"nz\", \"United States\": \"us\", \"USA\": \"us\",\n",
    "    \"Finland\": \"fi\", \"Austria\": \"at\", \"Qatar\": \"qa\", \"Taiwan\": \"tw\",\n",
    "    \"Ireland\": \"ie\", \"South Korea\": \"kr\", \"Korea, South\": \"kr\", \"Hong Kong\": \"hk\",\n",
    "    \"United Kingdom\": \"gb\", \"UK\": \"gb\", \"Belgium\": \"be\", \"Czech Republic\": \"cz\",\n",
    "    \"Czechia\": \"cz\", \"France\": \"fr\", \"Iceland\": \"is\", \"Slovenia\": \"si\",\n",
    "    \"Japan\": \"jp\", \"China\": \"cn\", \"Lithuania\": \"lt\", \"Malta\": \"mt\",\n",
    "    \"Chile\": \"cl\", \"Portugal\": \"pt\", \"Slovakia\": \"sk\", \"Poland\": \"pl\",\n",
    "    \"Spain\": \"es\", \"Croatia\": \"hr\", \"Cyprus\": \"cy\", \"Israel\": \"il\",\n",
    "    \"Malaysia\": \"my\", \"Botswana\": \"bw\", \"Bulgaria\": \"bg\", \"Philippines\": \"ph\",\n",
    "    \"Italy\": \"it\", \"Indonesia\": \"id\", \"Peru\": \"pe\", \"Kazakhstan\": \"kz\",\n",
    "    \"Mexico\": \"mx\", \"Hungary\": \"hu\", \"Greece\": \"gr\", \"India\": \"in\",\n",
    "    \"Mauritius\": \"mu\", \"Romania\": \"ro\", \"Colombia\": \"co\", \"Serbia\": \"rs\",\n",
    "    \"Morocco\": \"ma\", \"Vietnam\": \"vn\", \"Brazil\": \"br\", \"South Africa\": \"za\",\n",
    "    \"Jordan\": \"jo\", \"Namibia\": \"na\", \"Turkey\": \"tr\", \"Bangladesh\": \"bd\",\n",
    "    \"Bahrain\": \"bh\", \"Uganda\": \"ug\", \"Nigeria\": \"ng\", \"Egypt\": \"eg\",\n",
    "    \"Kenya\": \"ke\", \"Pakistan\": \"pk\", \"Sri Lanka\": \"lk\", \"Zambia\": \"zm\",\n",
    "    \"Ukraine\": \"ua\", \"Russia\": \"ru\"\n",
    "}\n",
    "\n",
    "# rating number → letter\n",
    "RATING_LABEL = {22:\"AAA\",21:\"AA+\",20:\"AA\",19:\"AA-\",18:\"A+\",17:\"A\",16:\"A-\",\n",
    "                15:\"BBB+\",14:\"BBB\",13:\"BBB-\",12:\"BB+\",11:\"BB\",10:\"BB-\",\n",
    "                 9:\"B+\",  8:\"B\",  7:\"B-\", 6:\"CCC+\",5:\"CCC\",4:\"CCC-\",\n",
    "                 3:\"CC\",  2:\"C\",  1:\"D\"}\n",
    "\n",
    "# ---------------------------------------------------------------- helpers ----\n",
    "def load_icon(code: str):\n",
    "    png = ICON_DIR / f\"{code}.png\"\n",
    "    return plt.imread(png) if png.exists() else None\n",
    "\n",
    "# ---------------------------------------------------------------- main plot --\n",
    "def create_plot(outfile=\"bond_spreads_vs_ratings.png\",\n",
    "                jitter_x=5, label_dx=8, flag_height=24):\n",
    "\n",
    "    # ---------- style ------------------------------------------------------\n",
    "    mpl.rcParams.update({\n",
    "        \"figure.figsize\": (12, 12),\n",
    "        \"axes.titlesize\": 40, \"axes.labelsize\": 32,\n",
    "        \"xtick.labelsize\": 24, \"ytick.labelsize\": 24,\n",
    "        \"legend.fontsize\": 24,\n",
    "        \"font.family\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\", \"sans-serif\"],\n",
    "    })\n",
    "    palette = sns.color_palette(\"bright\", 3)\n",
    "    rng      = np.random.default_rng()\n",
    "\n",
    "    # ---------- data -------------------------------------------------------\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    df[\"Spread_Numeric\"] = (df[\"Spread\"].astype(str)\n",
    "                                         .str.replace(r\"[^\\d.\\-]\", \"\", regex=True)\n",
    "                                         .replace(\"\", np.nan).astype(float))\n",
    "    for col in [\"S&P_Numeric\", \"Moody's_Numeric\", \"Fitch_Numeric\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = (df[col].astype(str)\n",
    "                                   .str.replace(r\"[^\\d.\\-]\", \"\", regex=True)\n",
    "                                   .replace(\"\", np.nan).astype(float))\n",
    "\n",
    "    # ---------- scatter & ties --------------------------------------------\n",
    "    fig, ax = plt.subplots()\n",
    "    per_ctry = {}\n",
    "\n",
    "    all_x_vals = []\n",
    "    all_y_vals = []\n",
    "\n",
    "    for colour, (col, lbl) in zip(\n",
    "            palette,\n",
    "            [(\"S&P_Numeric\",\"S&P\"),(\"Moody's_Numeric\",\"Moody's\"),\n",
    "             (\"Fitch_Numeric\",\"Fitch\")]):\n",
    "\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        sub = df.dropna(subset=[col, \"Spread_Numeric\"])\n",
    "\n",
    "        jitter_x_vals = sub[\"Spread_Numeric\"] + rng.normal(0, jitter_x, len(sub))\n",
    "        y_vals        = sub[col]\n",
    "\n",
    "        ax.scatter(jitter_x_vals, y_vals, s=140, c=[colour],\n",
    "                   alpha=.85, label=lbl)\n",
    "\n",
    "        all_x_vals.extend(sub[\"Spread_Numeric\"].tolist())\n",
    "        all_y_vals.extend(y_vals.tolist())\n",
    "\n",
    "        for ctry, x0, y0 in zip(sub[\"Country\"], sub[\"Spread_Numeric\"], sub[col]):\n",
    "            d = per_ctry.setdefault(ctry, {\"x\":x0, \"ys\":[]})\n",
    "            d[\"ys\"].append(y0)\n",
    "\n",
    "    # vertical tie lines\n",
    "    for d in per_ctry.values():\n",
    "        if len(d[\"ys\"]) > 1:\n",
    "            ax.plot([d[\"x\"], d[\"x\"]], [min(d[\"ys\"]), max(d[\"ys\"])],\n",
    "                    color=\"grey\", lw=2, alpha=.55, zorder=2)\n",
    "\n",
    "    # ---------- correlation line ------------------------------------------\n",
    "    x_arr = np.array(all_x_vals)\n",
    "    y_arr = np.array(all_y_vals)\n",
    "    # fit linear regression\n",
    "    m, b = np.polyfit(x_arr, y_arr, 1)\n",
    "    xs = np.linspace(x_arr.min(), x_arr.max(), 100)\n",
    "    ax.plot(xs, m*xs + b, color='black', lw=2, linestyle='--', zorder=1)\n",
    "    # compute correlation coefficient\n",
    "    corr = np.corrcoef(x_arr, y_arr)[0, 1]\n",
    "    ax.text(0.95, 0.05, f\"r = {corr:.2f}\", transform=ax.transAxes,\n",
    "            ha='right', va='bottom', fontsize=20, backgroundcolor='white', alpha=0.7)\n",
    "\n",
    "    # ---------- flag or code labels ---------------------------------------\n",
    "    for _, row in df.iterrows():\n",
    "        ctry = row[\"Country\"]\n",
    "        code = COUNTRY_TO_CODE.get(ctry, ctry[:2].lower())\n",
    "        x    = row[\"Spread_Numeric\"]\n",
    "        y    = np.nanmax([row.get(c) for c in\n",
    "                         [\"S&P_Numeric\",\"Moody's_Numeric\",\"Fitch_Numeric\"]])\n",
    "\n",
    "        lx, ly = x + label_dx, y\n",
    "        icon   = load_icon(code)\n",
    "\n",
    "        if icon is not None:\n",
    "            zoom = flag_height / icon.shape[0]\n",
    "            ab = AnnotationBbox(OffsetImage(icon, zoom=zoom),\n",
    "                                (lx, ly), frameon=False,\n",
    "                                box_alignment=(0,.5), zorder=4)\n",
    "            ax.add_artist(ab)\n",
    "        else:\n",
    "            ax.text(lx, ly, code.upper(), fontsize=14, fontweight=\"bold\",\n",
    "                    va=\"center\", zorder=4)\n",
    "\n",
    "    # ---------- shaded background -----------------------------------------\n",
    "    ax.axhspan(13, 22, color=\"#cce6ff\", alpha=.25, zorder=0)   # investment\n",
    "    ax.axhspan( 1, 13, color=\"#e8d5ff\", alpha=.25, zorder=0)   # speculative\n",
    "    ax.text(ax.get_xlim()[1]*.985, 13.2, \"Investment Grade\",\n",
    "            ha=\"right\", va=\"bottom\", color=\"navy\", fontsize=18, alpha=.8)\n",
    "    ax.text(ax.get_xlim()[1]*.985, 12.8, \"Speculative Grade\",\n",
    "            ha=\"right\", va=\"top\", color=\"#5e3b7f\", fontsize=18, alpha=.8)\n",
    "\n",
    "    # ---------- Y-axis letters --------------------------------------------\n",
    "    ticks = range(1,23)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels([RATING_LABEL[t] for t in ticks])\n",
    "\n",
    "    # ---------- cosmetics --------------------------------------------------\n",
    "    ax.set_xlabel(\"10-Year Bond Spread to US (bp)\")\n",
    "    ax.set_ylabel(\"Credit Rating\")\n",
    "    ax.set_title(\"Bond Spreads vs. Sovereign Credit Ratings\", pad=45, fontweight='bold')\n",
    "\n",
    "    pad = (x_arr.max() - x_arr.min()) * .05\n",
    "    ax.set_xlim(x_arr.min()-pad, x_arr.max()+pad)\n",
    "    # start y-axis at zero equivalent to show D grades clearly\n",
    "    ax.set_ylim(0, 23.5)\n",
    "\n",
    "    ax.axvline(0, color=\"black\", lw=2, alpha=.4)\n",
    "    ax.grid(alpha=.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outfile, dpi=300, bbox_inches=\"tight\")\n",
    "    print(\"✅  Saved →\", outfile)\n",
    "\n",
    "# ---------------------------------------------------------------- run ---------\n",
    "if __name__ == \"__main__\":\n",
    "    if not CSV_FILE.exists():\n",
    "        sys.exit(\"❌  credit_ratings_and_spreads.csv not found.\")\n",
    "    create_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4395344-8614-4de5-a7e2-160757c0a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1937a3de-1d1a-44d5-98a3-e3765b99438d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved → investment_grade_plot.png with dimensions 3732 × 3566 pixels\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Investment‑grade bond spreads vs. sovereign credit ratings - FINAL VERSION\n",
    "\n",
    "• BBB (14) to AAA only — BBB is the lowest rating shown\n",
    "• Square 12 × 12‑inch figure, doubled fonts (same look as full plot)\n",
    "• Vertical x = 0 reference line, investment‑grade shading\n",
    "• Vertical ties between multiple agency ratings per country\n",
    "• PNG flags (or ISO fallback) as labels with vertical jitter\n",
    "• Dashed correlation line with Pearson r in lower‑right\n",
    "• X‑axis fixed at ±500 bp\n",
    "• Exactly matching original display with no white space issues\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# ---------------------------------------------------------------- paths -------\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:  # Jupyter or interactive\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "CSV_FILE = BASE_DIR / \"credit_ratings_and_spreads.csv\"\n",
    "ICON_DIR = BASE_DIR / \"flag_icons\"\n",
    "\n",
    "# ---------------------------------------------------------------- ISO map ----\n",
    "COUNTRY_TO_CODE = {\n",
    "    \"Switzerland\": \"ch\", \"Singapore\": \"sg\", \"Norway\": \"no\", \"Netherlands\": \"nl\",\n",
    "    \"Germany\": \"de\", \"Australia\": \"au\", \"Sweden\": \"se\", \"Denmark\": \"dk\",\n",
    "    \"Canada\": \"ca\", \"New Zealand\": \"nz\", \"United States\": \"us\", \"USA\": \"us\",\n",
    "    \"Finland\": \"fi\", \"Austria\": \"at\", \"Qatar\": \"qa\", \"Taiwan\": \"tw\",\n",
    "    \"Ireland\": \"ie\", \"South Korea\": \"kr\", \"Korea, South\": \"kr\", \"Hong Kong\": \"hk\",\n",
    "    \"United Kingdom\": \"gb\", \"UK\": \"gb\", \"Belgium\": \"be\", \"Czech Republic\": \"cz\",\n",
    "    \"Czechia\": \"cz\", \"France\": \"fr\", \"Iceland\": \"is\", \"Slovenia\": \"si\",\n",
    "    \"Japan\": \"jp\", \"China\": \"cn\", \"Lithuania\": \"lt\", \"Malta\": \"mt\",\n",
    "    \"Chile\": \"cl\", \"Portugal\": \"pt\", \"Slovakia\": \"sk\", \"Poland\": \"pl\",\n",
    "    \"Spain\": \"es\", \"Croatia\": \"hr\", \"Cyprus\": \"cy\", \"Israel\": \"il\",\n",
    "    \"Malaysia\": \"my\", \"Botswana\": \"bw\", \"Bulgaria\": \"bg\", \"Philippines\": \"ph\",\n",
    "    \"Italy\": \"it\", \"Indonesia\": \"id\", \"Peru\": \"pe\", \"Kazakhstan\": \"kz\",\n",
    "    \"Mexico\": \"mx\", \"Hungary\": \"hu\", \"Greece\": \"gr\", \"India\": \"in\",\n",
    "    \"Mauritius\": \"mu\", \"Romania\": \"ro\", \"Colombia\": \"co\", \"Serbia\": \"rs\",\n",
    "    \"Morocco\": \"ma\", \"Vietnam\": \"vn\", \"Brazil\": \"br\", \"South Africa\": \"za\",\n",
    "    \"Jordan\": \"jo\", \"Namibia\": \"na\", \"Turkey\": \"tr\", \"Bangladesh\": \"bd\",\n",
    "    \"Bahrain\": \"bh\", \"Uganda\": \"ug\", \"Nigeria\": \"ng\", \"Egypt\": \"eg\",\n",
    "    \"Kenya\": \"ke\", \"Pakistan\": \"pk\", \"Sri Lanka\": \"lk\", \"Zambia\": \"zm\",\n",
    "    \"Ukraine\": \"ua\", \"Russia\": \"ru\"\n",
    "}\n",
    "\n",
    "# rating number → letter\n",
    "RATING_LABEL = {\n",
    "    14: \"BBB\", 15: \"BBB+\", 16: \"A-\", 17: \"A\", 18: \"A+\",\n",
    "    19: \"AA-\", 20: \"AA\", 21: \"AA+\", 22: \"AAA\"\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------- helpers ----\n",
    "def load_icon(code: str):\n",
    "    png = ICON_DIR / f\"{code}.png\"\n",
    "    return plt.imread(png) if png.exists() else None\n",
    "\n",
    "# ---------------------------------------------------------------- plot --------\n",
    "def create_investment_plot(outfile=\"investment_grade_plot.png\",\n",
    "                           jitter_x=5, label_dx=8, flag_height=24):\n",
    "    \"\"\"Create perfect square plot matching original dimensions exactly: 3732 × 3566 pixels\"\"\"\n",
    "    \n",
    "    # Calculate figure size to get exact pixel dimensions at 300 dpi\n",
    "    # Original dimensions: 3732 × 3566 pixels at 300 dpi\n",
    "    # Figure size in inches = pixels / dpi\n",
    "    width_inches = 3732 / 300\n",
    "    height_inches = 3566 / 300\n",
    "    \n",
    "    # Reset any previous matplotlib settings\n",
    "    mpl.rcdefaults()\n",
    "    \n",
    "    # Set global font settings\n",
    "    plt.rcParams.update({\n",
    "        'font.family': [\"Arial\", \"Helvetica\", \"DejaVu Sans\", \"sans-serif\"],\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 40, \n",
    "        'axes.labelsize': 32,\n",
    "        'xtick.labelsize': 24, \n",
    "        'ytick.labelsize': 24,\n",
    "        'legend.fontsize': 24,\n",
    "    })\n",
    "    \n",
    "    # Use fixed seed for reproducibility\n",
    "    rng = np.random.default_rng(42)\n",
    "    palette = sns.color_palette(\"bright\", 3)\n",
    "    \n",
    "    # ---------- data -------------------------------------------------------\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    df[\"Spread_Numeric\"] = (df[\"Spread\"].astype(str)\n",
    "                             .str.replace(r\"[^\\d.\\-]\", \"\", regex=True)\n",
    "                             .replace(\"\", np.nan).astype(float))\n",
    "\n",
    "    agency_cols = []\n",
    "    for col in [\"S&P_Numeric\", \"Moody's_Numeric\", \"Fitch_Numeric\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = (df[col].astype(str)\n",
    "                       .str.replace(r\"[^\\d.\\-]\", \"\", regex=True)\n",
    "                       .replace(\"\", np.nan).astype(float))\n",
    "            agency_cols.append(col)\n",
    "\n",
    "    # Keep only BBB (14) and higher\n",
    "    df = df[df[agency_cols].max(axis=1) >= 14]\n",
    "    \n",
    "    # ---------- figure with precise dimensions -----------------------------\n",
    "    # Use exact dimensions to match original at 300 dpi\n",
    "    fig = plt.figure(figsize=(width_inches, height_inches))\n",
    "    \n",
    "    # Use exact positioning for the plot area - key to prevent whitespace issues\n",
    "    ax = fig.add_axes([0.12, 0.12, 0.78, 0.75])  # left, bottom, width, height\n",
    "    \n",
    "    # ---------- scatter & ties --------------------------------------------\n",
    "    per_ctry = {}\n",
    "    all_x, all_y = [], []\n",
    "\n",
    "    # Plot each agency's ratings\n",
    "    for colour, (col, lbl) in zip(\n",
    "            palette,\n",
    "            [(c, c.split('_')[0]) for c in agency_cols]):\n",
    "        \n",
    "        sub = df.dropna(subset=[col, \"Spread_Numeric\"])\n",
    "        jittered = sub[\"Spread_Numeric\"] + rng.normal(0, jitter_x, len(sub))\n",
    "        y_vals = sub[col]\n",
    "        \n",
    "        ax.scatter(jittered, y_vals, s=140, c=[colour], alpha=.85, label=lbl)\n",
    "        \n",
    "        all_x.extend(sub[\"Spread_Numeric\"].tolist())\n",
    "        all_y.extend(y_vals.tolist())\n",
    "        \n",
    "        for ctry, x0, y0 in zip(sub[\"Country\"], sub[\"Spread_Numeric\"], sub[col]):\n",
    "            d = per_ctry.setdefault(ctry, {\"x\": x0, \"ys\": []})\n",
    "            d[\"ys\"].append(y0)\n",
    "\n",
    "    # Vertical tie lines between multiple agency ratings for same country\n",
    "    for d in per_ctry.values():\n",
    "        if len(d[\"ys\"]) > 1:\n",
    "            ax.plot([d[\"x\"], d[\"x\"]], [min(d[\"ys\"]), max(d[\"ys\"])],\n",
    "                    color=\"grey\", lw=2, alpha=.55, zorder=2)\n",
    "\n",
    "    # ---------- correlation line ------------------------------------------\n",
    "    x_arr, y_arr = np.array(all_x), np.array(all_y)\n",
    "    m, b = np.polyfit(x_arr, y_arr, 1)\n",
    "    xs = np.linspace(-500, 500, 300)\n",
    "    ax.plot(xs, m*xs + b, linestyle=\"--\", lw=2, color=\"black\", zorder=1)\n",
    "    r = np.corrcoef(x_arr, y_arr)[0, 1]\n",
    "    \n",
    "    # Correlation text properly positioned\n",
    "    ax.text(0.95, 0.05, f\"r = {r:.2f}\", transform=ax.transAxes,\n",
    "            ha=\"right\", va=\"bottom\", fontsize=20, \n",
    "            bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'),\n",
    "            zorder=5)\n",
    "\n",
    "    # ---------- flag or code labels with vertical jitter ------------------\n",
    "    used_positions = {}  # Track flag positions to avoid overlap\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        ctry = row[\"Country\"]\n",
    "        code = COUNTRY_TO_CODE.get(ctry, ctry[:2].lower())\n",
    "        x = row[\"Spread_Numeric\"]\n",
    "        y = np.nanmax([row.get(c, np.nan) for c in agency_cols])\n",
    "        \n",
    "        # Skip if invalid data\n",
    "        if np.isnan(y) or np.isnan(x):\n",
    "            continue\n",
    "        \n",
    "        # Calculate base position\n",
    "        lx = x + label_dx\n",
    "        ly = y\n",
    "        \n",
    "        # Apply vertical jitter based on nearby flags\n",
    "        key_x = round(x / 20) * 20  # Round to identify nearby flags\n",
    "        nearby_count = 0\n",
    "        \n",
    "        for test_y in range(int(y) - 1, int(y) + 2):\n",
    "            if (key_x, test_y) in used_positions:\n",
    "                nearby_count += used_positions[(key_x, test_y)]\n",
    "        \n",
    "        # Apply smart jitter to avoid overlaps\n",
    "        if nearby_count > 0:\n",
    "            jitter_direction = 1 if nearby_count % 2 == 1 else -1\n",
    "            jitter_amount = (nearby_count // 2 + 1) * 0.3\n",
    "            ly += jitter_direction * jitter_amount\n",
    "        \n",
    "        # Record this position\n",
    "        used_positions[(key_x, int(y))] = used_positions.get((key_x, int(y)), 0) + 1\n",
    "        \n",
    "        # Add flag or ISO code\n",
    "        icon = load_icon(code)\n",
    "        if icon is not None:\n",
    "            zoom = flag_height / icon.shape[0]\n",
    "            ab = AnnotationBbox(OffsetImage(icon, zoom=zoom), (lx, ly),\n",
    "                               frameon=False, box_alignment=(0, 0.5), zorder=4)\n",
    "            ax.add_artist(ab)\n",
    "        else:\n",
    "            ax.text(lx, ly, code.upper(), fontsize=14, fontweight=\"bold\", \n",
    "                   va=\"center\", zorder=4)\n",
    "\n",
    "    # ---------- shaded background -----------------------------------------\n",
    "    ax.axhspan(14, 22, color=\"#cce6ff\", alpha=.25, zorder=0)\n",
    "    \n",
    "    # Investment Grade label properly positioned\n",
    "    ax.text(460, 14.2, \"Investment Grade\", ha=\"right\", va=\"bottom\",\n",
    "           color=\"navy\", fontsize=18, alpha=.8, zorder=5)\n",
    "\n",
    "    # ---------- Y-axis letters --------------------------------------------\n",
    "    ax.set_yticks(list(RATING_LABEL.keys()))\n",
    "    ax.set_yticklabels(list(RATING_LABEL.values()))\n",
    "\n",
    "    # ---------- cosmetics -------------------------------------------------\n",
    "    ax.set_xlabel(\"10-Year Bond Spread to US (bp)\")\n",
    "    ax.set_ylabel(\"Credit Rating\")\n",
    "    \n",
    "    # Place title directly on figure with precise position control\n",
    "    fig.text(0.5, 0.94, \"Bond Spreads vs. Sovereign Credit Ratings\", \n",
    "            ha='center', fontsize=40, fontweight='bold')\n",
    "    fig.text(0.5, 0.89, \"Investment grade\", \n",
    "            ha='center', fontsize=32)\n",
    "\n",
    "    # Set exact axes limits\n",
    "    ax.set_xlim(-500, 500)\n",
    "    ax.set_ylim(13.8, 22.5)\n",
    "\n",
    "    # Reference line at x=0\n",
    "    ax.axvline(0, color=\"black\", lw=2, alpha=.4)\n",
    "    ax.grid(alpha=.3)\n",
    "    \n",
    "    # Legend in upper right, properly positioned\n",
    "    ax.legend(loc='upper right', framealpha=0.9)\n",
    "    \n",
    "    # Ensure truly square data area\n",
    "    ax.set_aspect('auto')\n",
    "    \n",
    "    # Save with exact dimensions\n",
    "    fig.savefig(outfile, dpi=300, facecolor='white', edgecolor='none')\n",
    "    \n",
    "    # Verify the output file dimensions\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        img = Image.open(outfile)\n",
    "        print(f\"✅  Saved → {outfile} with dimensions {img.size[0]} × {img.size[1]} pixels\")\n",
    "    except ImportError:\n",
    "        print(f\"✅  Saved → {outfile}\")\n",
    "        print(f\"    Expected dimensions: 3732 × 3566 pixels\")\n",
    "        print(f\"    (Install PIL/Pillow to verify image dimensions)\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------- run ---------\n",
    "if __name__ == \"__main__\":\n",
    "    if not CSV_FILE.exists():\n",
    "        sys.exit(\"❌  credit_ratings_and_spreads.csv not found.\")\n",
    "    create_investment_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783d4c2-200c-476c-beea-b83abcc7d15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055433c-32c9-4c72-9c73-4a1e8ae1e6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etheryx",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
